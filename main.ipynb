{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection System - Main Entry Point\n",
    "\n",
    "This notebook serves as the main entry point for the anomaly detection system. It provides functions to:\n",
    "- Train a new model\n",
    "- Load and evaluate existing models\n",
    "- Make predictions on new images\n",
    "- Analyze model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "from solar_model import (\n",
    "    train_and_evaluate,\n",
    "    evaluate_existing_model,\n",
    "    predict_single_image,\n",
    "    load_best_model\n",
    ")\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Logging Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_dir=\"logs\"):\n",
    "    \"\"\"\n",
    "    Configure logging to both file and console\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "        \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = os.path.join(log_dir, f\"anomaly_detection_{timestamp}.log\")\n",
    "    \n",
    "    # Configure logging format\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"Logging configured. Log file: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \"\"\"\n",
    "    Train a new model and save results\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting model training...\")\n",
    "    \n",
    "    try:\n",
    "        model, label_encoder, history = train_and_evaluate()\n",
    "        \n",
    "        # Save training history\n",
    "        history_file = os.path.join(cfg.CHECKPOINT_DIR, 'training_history.json')\n",
    "        history_dict = {\n",
    "            'loss': [float(x) for x in history.history['loss']],\n",
    "            'accuracy': [float(x) for x in history.history['accuracy']],\n",
    "            'val_loss': [float(x) for x in history.history['val_loss']],\n",
    "            'val_accuracy': [float(x) for x in history.history['val_accuracy']]\n",
    "        }\n",
    "        \n",
    "        with open(history_file, 'w') as f:\n",
    "            json.dump(history_dict, f, indent=4)\n",
    "        \n",
    "        logging.info(f\"Training history saved to {history_file}\")\n",
    "        logging.info(\"Model training completed successfully\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during model training: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path=None):\n",
    "    \"\"\"\n",
    "    Evaluate an existing model\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting model evaluation...\")\n",
    "    \n",
    "    try:\n",
    "        if model_path is None:\n",
    "            model_path = cfg.MODEL_SAVE_PATH\n",
    "        \n",
    "        accuracy, report = evaluate_existing_model(model_path)\n",
    "        \n",
    "        # Save evaluation results\n",
    "        results = {\n",
    "            'accuracy': float(accuracy),\n",
    "            'classification_report': report,\n",
    "            'evaluation_timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        results_file = os.path.join(cfg.CHECKPOINT_DIR, 'evaluation_results.json')\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        \n",
    "        logging.info(f\"Evaluation results saved to {results_file}\")\n",
    "        logging.info(f\"Model accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during model evaluation: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model_path=None):\n",
    "    \"\"\"\n",
    "    Make prediction on a single image\n",
    "    \"\"\"\n",
    "    logging.info(f\"Making prediction for image: {image_path}\")\n",
    "    \n",
    "    try:\n",
    "        if model_path is None:\n",
    "            model_path = cfg.MODEL_SAVE_PATH\n",
    "            \n",
    "        predicted_class, confidence, class_scores = predict_single_image(\n",
    "            image_path, \n",
    "            model_path\n",
    "        )\n",
    "        \n",
    "        if predicted_class is not None:\n",
    "            # Save prediction results\n",
    "            results = {\n",
    "                'image_path': image_path,\n",
    "                'predicted_class': predicted_class,\n",
    "                'confidence': float(confidence),\n",
    "                'class_scores': {k: float(v) for k, v in class_scores.items()},\n",
    "                'prediction_timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            # Create predictions directory if it doesn't exist\n",
    "            pred_dir = os.path.join(cfg.CHECKPOINT_DIR, 'predictions')\n",
    "            if not os.path.exists(pred_dir):\n",
    "                os.makedirs(pred_dir)\n",
    "            \n",
    "            # Save prediction results\n",
    "            filename = f\"prediction_{os.path.basename(image_path)}.json\"\n",
    "            results_file = os.path.join(pred_dir, filename)\n",
    "            \n",
    "            with open(results_file, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            \n",
    "            logging.info(f\"Prediction results saved to {results_file}\")\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during prediction: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Interface\n",
    "\n",
    "You can run this notebook as a script with the following command line arguments:\n",
    "- `--train`: Train a new model\n",
    "- `--evaluate`: Evaluate an existing model\n",
    "- `--predict`: Make prediction on a single image\n",
    "- `--model_path`: Path to the model file (optional)\n",
    "- `--image_path`: Path to the image file (required for prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    Parse command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Anomaly Detection System')\n",
    "    \n",
    "    parser.add_argument('--train', action='store_true',\n",
    "                      help='Train a new model')\n",
    "    \n",
    "    parser.add_argument('--evaluate', action='store_true',\n",
    "                      help='Evaluate an existing model')\n",
    "    \n",
    "    parser.add_argument('--predict', action='store_true',\n",
    "                      help='Make prediction on a single image')\n",
    "    \n",
    "    parser.add_argument('--model_path', type=str,\n",
    "                      help='Path to the model file')\n",
    "    \n",
    "    parser.add_argument('--image_path', type=str,\n",
    "                      help='Path to the image file')\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main entry point for the application\n",
    "    \"\"\"\n",
    "    # Set up logging\n",
    "    setup_logging()\n",
    "    \n",
    "    # Parse command line arguments\n",
    "    args = parse_arguments()\n",
    "    \n",
    "    if args.train:\n",
    "        logging.info(\"Starting training process...\")\n",
    "        success = train_model()\n",
    "        if success:\n",
    "            logging.info(\"Training completed successfully\")\n",
    "        else:\n",
    "            logging.error(\"Training failed\")\n",
    "            \n",
    "    if args.evaluate:\n",
    "        logging.info(\"Starting evaluation process...\")\n",
    "        success = evaluate_model(args.model_path)\n",
    "        if success:\n",
    "            logging.info(\"Evaluation completed successfully\")\n",
    "        else:\n",
    "            logging.error(\"Evaluation failed\")\n",
    "            \n",
    "    if args.predict:\n",
    "        if args.image_path is None:\n",
    "            logging.error(\"Image path is required for prediction\")\n",
    "            return\n",
    "            \n",
    "        logging.info(\"Starting prediction process...\")\n",
    "        success = predict_image(args.image_path, args.model_path)\n",
    "        if success:\n",
    "            logging.info(\"Prediction completed successfully\")\n",
    "        else:\n",
    "            logging.error(\"Prediction failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's how to use the functions defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new model\n",
    "# main(['--train'])\n",
    "\n",
    "# Evaluate an existing model\n",
    "# main(['--evaluate', '--model_path', 'path/to/model.h5']) # can also be .pb\n",
    "\n",
    "# Make a prediction\n",
    "# main(['--predict', '--image_path', 'path/to/image.jpg'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
